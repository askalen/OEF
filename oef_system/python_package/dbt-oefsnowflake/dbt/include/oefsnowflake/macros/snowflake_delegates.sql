{#-- AUTO-GENERATED FILE - DO NOT EDIT MANUALLY --#}
{#-- Generated by update_macro_delegates.py --#}
{#-- This file contains oefsnowflake versions of all dbt-snowflake macros --#}

{#-- To regenerate this file, run: python scripts/update_macro_delegates.py --#}


{#-- BASE DISPATCHER MACRO --#}
{#-- This is needed because dbt core calls list_relations_without_caching directly --#}
{% macro list_relations_without_caching(schema_relation) %}
  {{ return(adapter.dispatch('list_relations_without_caching', 'dbt')(schema_relation)) }}
{% endmacro %}


{#-- ADAPTERS.SQL DISPATCHED MACROS --#}

{#-- From: macros\adapters.sql --#}
{% macro oefsnowflake__alter_relation_add_remove_columns(relation, add_columns, remove_columns) %}

    {% if relation.is_dynamic_table -%}
        {% set relation_type = "dynamic table" %}
    {% else -%}
        {% set relation_type = relation.type %}
    {% endif %}

    {% if add_columns %}

    {% set sql -%}
       alter {{ relation.get_ddl_prefix_for_alter() }} {{ relation_type }} {{ relation.render() }} add column
          {% for column in add_columns %}
            {{ column.name }} {{ column.data_type }}{{ ',' if not loop.last }}
          {% endfor %}
    {%- endset -%}

    {% do run_query(sql) %}

    {% endif %}

    {% if remove_columns %}

    {% set sql -%}
        alter {{ relation.get_ddl_prefix_for_alter() }} {{ relation_type }} {{ relation.render() }} drop column
            {% for column in remove_columns %}
                {{ column.name }}{{ ',' if not loop.last }}
            {% endfor %}
    {%- endset -%}

    {% do run_query(sql) %}

    {% endif %}

{% endmacro %}

{#-- From: macros\adapters.sql --#}
{% macro oefsnowflake__show_object_metadata(relation) %}
  {%- set sql -%}
    show objects in {{ relation.include(identifier=False) }} starts with '{{ relation.identifier }}' limit 1
  {%- endset -%}

  {%- set result = run_query(sql) -%}
  {{ return(result) }}
{% endmacro %}

{#-- ADAPTERS.SQL HELPER MACROS --#}

{#-- From: macros\adapters.sql --#}
{% macro get_persist_docs_column_list(model_columns, query_columns) %}
(
  {% for column_name in query_columns %}
    {{ get_column_comment_sql(column_name, model_columns) }}
    {{- ", " if not loop.last else "" }}
  {% endfor %}
)
{% endmacro %}

{#-- From: macros\adapters.sql --#}
{% macro snowflake_dml_explicit_transaction(dml) %}
  {#
    Use this macro to wrap all INSERT, MERGE, UPDATE, DELETE, and TRUNCATE
    statements before passing them into run_query(), or calling in the 'main' statement
    of a materialization
  #}
  {% set dml_transaction -%}
    begin;
    {{ dml }};
    commit;
  {%- endset %}

  {% do return(dml_transaction) %}

{% endmacro %}

{#-- APPLY_GRANTS.SQL DISPATCHED MACROS --#}

{#-- From: macros\apply_grants.sql --#}
{% macro oefsnowflake__copy_grants() %}
    {% set copy_grants = config.get('copy_grants', False) %}
    {{ return(copy_grants) }}
{% endmacro %}

{#-- CATALOG.SQL DISPATCHED MACROS --#}

{#-- From: macros\catalog.sql --#}
{% macro oefsnowflake__catalog_equals(field, value) %}
    "{{ field }}" ilike '{{ value }}' and upper("{{ field }}") = upper('{{ value }}')
{% endmacro %}

{#-- MATERIALIZATIONS DISPATCHED MACROS --#}

{#-- From: macros\materializations\clone.sql --#}
{% macro oefsnowflake__can_clone_table() %}
    {{ return(True) }}
{% endmacro %}

{#-- From: macros\materializations\clone.sql --#}
{% macro oefsnowflake__create_or_replace_clone(this_relation, defer_relation) %}
    create or replace
      {{ "transient" if config.get("transient", true) }}
      table {{ this_relation }}
      clone {{ defer_relation }}
      {{ "copy grants" if config.get("copy_grants", false) }}
{% endmacro %}

{#-- From: macros\materializations\incremental\merge.sql --#}
{% macro oefsnowflake__get_delete_insert_merge_sql(target, source, unique_key, dest_columns, incremental_predicates) %}
    {% set dml = default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns, incremental_predicates) %}
    {% do return(snowflake_dml_explicit_transaction(dml)) %}
{% endmacro %}

{#-- From: macros\materializations\incremental\merge.sql --#}
{% macro oefsnowflake__get_incremental_append_sql(get_incremental_append_sql) %}
    {% set dml = default__get_incremental_append_sql(get_incremental_append_sql) %}
    {% do return(snowflake_dml_explicit_transaction(dml)) %}
{% endmacro %}

{#-- From: macros\materializations\incremental.sql --#}
{% macro oefsnowflake__get_incremental_default_sql(arg_dict) %}
  {{ return(get_incremental_merge_sql(arg_dict)) }}
{% endmacro %}

{#-- From: macros\materializations\incremental\merge.sql --#}
{% macro oefsnowflake__get_incremental_microbatch_sql(arg_dict) %}
    {%- set target = arg_dict["target_relation"] -%}
    {%- set source = arg_dict["temp_relation"] -%}
    {%- set dest_columns = arg_dict["dest_columns"] -%}
    {%- set incremental_predicates = [] if arg_dict.get('incremental_predicates') is none else arg_dict.get('incremental_predicates') -%}

    {#-- Add additional incremental_predicates to filter for batch --#}
    {% if model.batch and model.batch.event_time_start -%}
        {% do incremental_predicates.append("DBT_INTERNAL_TARGET." ~ model.config.event_time ~ " >= to_timestamp_tz('" ~ model.config.__dbt_internal_microbatch_event_time_start ~ "')") %}
    {% endif %}
    {% if model.batch and model.batch.event_time_end -%}
        {% do incremental_predicates.append("DBT_INTERNAL_TARGET." ~ model.config.event_time ~ " < to_timestamp_tz('" ~ model.config.__dbt_internal_microbatch_event_time_end ~ "')") %}
    {% endif %}
    {% do arg_dict.update({'incremental_predicates': incremental_predicates}) %}

    delete from {{ target }} DBT_INTERNAL_TARGET
    where (
    {% for predicate in incremental_predicates %}
        {%- if not loop.first %}and {% endif -%} {{ predicate }}
    {% endfor %}
    );

    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute="name")) -%}
    insert into {{ target }} ({{ dest_cols_csv }})
    (
        select {{ dest_cols_csv }}
        from {{ source }}
    )
{% endmacro %}

{#-- From: macros\materializations\seed.sql --#}
{% macro oefsnowflake__load_csv_rows(model, agate_table) %}
    {% set batch_size = get_batch_size() %}
    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}
    {% set bindings = [] %}

    {% set statements = [] %}

    {% for chunk in agate_table.rows | batch(batch_size) %}
        {% set bindings = [] %}

        {% for row in chunk %}
            {% do bindings.extend(row) %}
        {% endfor %}

        {% set sql %}
            insert into {{ this.render() }} ({{ cols_sql }}) values
            {% for row in chunk -%}
                ({%- for column in agate_table.column_names -%}
                    %s
                    {%- if not loop.last%},{%- endif %}
                {%- endfor -%})
                {%- if not loop.last%},{%- endif %}
            {%- endfor %}
        {% endset %}

        {% do adapter.add_query('BEGIN', auto_begin=False) %}
        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}
        {% do adapter.add_query('COMMIT', auto_begin=False) %}

        {% if loop.index0 == 0 %}
            {% do statements.append(sql) %}
        {% endif %}
    {% endfor %}

    {# Return SQL so we can render it out into the compiled files #}
    {{ return(statements[0]) }}
{% endmacro %}

{#-- From: macros\materializations\incremental\merge.sql --#}
{% macro oefsnowflake__snapshot_merge_sql(target, source, insert_cols) %}
    {% set dml = default__snapshot_merge_sql(target, source, insert_cols) %}
    {% do return(snowflake_dml_explicit_transaction(dml)) %}
{% endmacro %}

{#-- MATERIALIZATIONS HELPER MACROS --#}

{#-- From: macros\materializations\incremental.sql --#}
{% macro dbt_snowflake_get_tmp_relation_type(strategy, unique_key, language) %}
{%- set tmp_relation_type = config.get('tmp_relation_type') -%}
  /* {#
       High-level principles:
       If we are running multiple statements (DELETE + INSERT),
       and we want to guarantee identical inputs to both statements,
       then we must first save the model query results as a temporary table
       (which presumably comes with a performance cost).
       If we are running a single statement (MERGE or INSERT alone),
       we _may_ save the model query definition as a view instead,
       for (presumably) faster overall incremental processing.

       Low-level specifics:
       If an invalid option is specified, then we will raise an
       excpetion with corresponding message.

       Languages other than SQL (like Python) will use a temporary table.
       With the default strategy of merge, the user may choose between a temporary
       table and view (defaulting to view).

       The append strategy can use a view because it will run a single INSERT statement.

       When unique_key is none, the delete+insert and microbatch strategies can use a view beacuse a
       single INSERT statement is run with no DELETES as part of the statement.
       Otherwise, play it safe by using a temporary table.
  #} */

  {% if language == "python" and tmp_relation_type is not none %}
    {% do exceptions.raise_compiler_error(
      "Python models currently only support 'table' for tmp_relation_type but "
       ~ tmp_relation_type ~ " was specified."
    ) %}
  {% endif %}

  {% if strategy in ["delete+insert", "microbatch"] and tmp_relation_type is not none and tmp_relation_type != "table" and unique_key is not none %}
    {% do exceptions.raise_compiler_error(
      "In order to maintain consistent results when `unique_key` is not none,
      the `" ~ strategy ~ "` strategy only supports `table` for `tmp_relation_type` but "
      ~ tmp_relation_type ~ " was specified."
      )
  %}
  {% endif %}

  {% if language != "sql" %}
    {{ return("table") }}
  {% elif tmp_relation_type == "table" %}
    {{ return("table") }}
  {% elif tmp_relation_type == "view" %}
    {{ return("view") }}
  {% elif strategy in ("default", "merge", "append", "insert_overwrite") %}
    {{ return("view") }}
  {% elif strategy in ["delete+insert", "microbatch"] and unique_key is none %}
    {{ return("view") }}
  {% else %}
    {{ return("table") }}
  {% endif %}
{% endmacro %}

{#-- From: macros\materializations\dynamic_table.sql --#}
{% macro dynamic_table_execute_build_sql(build_sql, existing_relation, target_relation) %}

    {% set grant_config = config.get('grants') %}

    {% call statement(name="main") %}
        {{ build_sql }}
    {% endcall %}

    {% set should_revoke = should_revoke(existing_relation, full_refresh_mode=True) %}
    {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}

    {% do persist_docs(target_relation, model) %}

{% endmacro %}

{#-- From: macros\materializations\dynamic_table.sql --#}
{% macro dynamic_table_execute_no_op(relation) %}
    {% do store_raw_result(
        name="main",
        message="skip " ~ relation,
        code="skip",
        rows_affected="-1"
    ) %}
{% endmacro %}

{#-- From: macros\materializations\dynamic_table.sql --#}
{% macro dynamic_table_get_build_sql(existing_relation, target_relation) %}

    {% set full_refresh_mode = should_full_refresh() %}

    -- determine the scenario we're in: create, full_refresh, alter, refresh data
    {% if existing_relation is none %}
        {% set build_sql = get_create_sql(target_relation, sql) %}
    {% elif full_refresh_mode or not existing_relation.is_dynamic_table %}
        {% set build_sql = get_replace_sql(existing_relation, target_relation, sql) %}
    {% else %}

        -- get config options
        {% set on_configuration_change = config.get('on_configuration_change') %}
        {% set configuration_changes = oefsnowflake__get_dynamic_table_configuration_changes(existing_relation, config) %}

        {% if configuration_changes is none %}
            {% set build_sql = '' %}
            {{ exceptions.warn("No configuration changes were identified on: `" ~ target_relation ~ "`. Continuing.") }}

        {% elif on_configuration_change == 'apply' %}
            {% set build_sql = oefsnowflake__get_alter_dynamic_table_as_sql(existing_relation, configuration_changes, target_relation, sql) %}
        {% elif on_configuration_change == 'continue' %}
            {% set build_sql = '' %}
            {{ exceptions.warn("Configuration changes were identified and `on_configuration_change` was set to `continue` for `" ~ target_relation ~ "`") }}
        {% elif on_configuration_change == 'fail' %}
            {{ exceptions.raise_fail_fast_error("Configuration changes were identified and `on_configuration_change` was set to `fail` for `" ~ target_relation ~ "`") }}

        {% else %}
            -- this only happens if the user provides a value other than `apply`, 'continue', 'fail'
            {{ exceptions.raise_compiler_error("Unexpected configuration scenario: `" ~ on_configuration_change ~ "`") }}

        {% endif %}

    {% endif %}

    {% do return(build_sql) %}

{% endmacro %}

{#-- METADATA DISPATCHED MACROS --#}

{#-- From: macros\metadata\list_relations_without_caching.sql --#}
{% macro oefsnowflake__list_relations_without_caching(schema_relation, max_iter=10000, max_results_per_iter=10000) %}

    {%- if schema_relation is string -%}
        {%- set schema = schema_relation -%}
    {%- else -%}
        {%- set schema = schema_relation.include(identifier=False) -%}
    {%- endif -%}

    {%- set max_results_per_iter = adapter.config.flags.get('list_relations_per_page', max_results_per_iter) -%}
    {%- set max_iter = adapter.config.flags.get('list_relations_page_limit', max_iter) -%}
    {%- set too_many_relations_msg -%}
        dbt is currently configured to list a maximum of {{ max_results_per_iter * max_iter }} objects per schema.
        {{ schema }} exceeds this limit. If this is expected, you may configure this limit
        by setting list_relations_per_page and list_relations_page_limit in your project flags.
        It is recommended to start by increasing list_relations_page_limit.
    {%- endset -%}

    {%- set paginated_state = namespace(paginated_results=[], watermark=none) -%}

    {%- do run_query('alter session set quoted_identifiers_ignore_case = false;') -%}

    {#-
        loop an extra time to catch the breach of max iterations
        Note: while range is 0-based, loop.index starts at 1
    -#}
    {%- for _ in range(max_iter + 1) -%}

        {#-
            raise a warning and break if we still didn't exit and we're beyond the max iterations limit
            Note: while range is 0-based, loop.index starts at 1
        -#}
        {%- if loop.index == max_iter + 1 -%}
            {%- do exceptions.warn(too_many_relations_msg) -%}
            {%- break -%}
        {%- endif -%}

        {%- set show_objects_sql = oefsnowflake__show_objects_sql(schema, max_results_per_iter, paginated_state.watermark) -%}
        {%- set paginated_result = run_query(show_objects_sql) -%}
        {%- do paginated_state.paginated_results.append(paginated_result) -%}
        {%- set paginated_state.watermark = paginated_result.columns.get('name').values()[-1] -%}

        {#- we got less results than the max_results_per_iter (includes 0), meaning we reached the end -#}
        {%- if (paginated_result | length) < max_results_per_iter -%}
            {%- break -%}
        {%- endif -%}

    {%- endfor -%}

    {%- do run_query('alter session unset quoted_identifiers_ignore_case;') -%}

    {#- grab the first table in the paginated results to access the `merge` method -#}
    {%- set agate_table = paginated_state.paginated_results[0] -%}
    {%- do return(agate_table.merge(paginated_state.paginated_results)) -%}

{% endmacro %}

{#-- From: macros\metadata\list_relations_without_caching.sql --#}
{% macro oefsnowflake__show_objects_sql(schema, max_results_per_iter=10000, watermark=none) %}

{%- set _sql -%}
show objects in {{ schema }}
    limit {{ max_results_per_iter }}
    {% if watermark is not none -%} from '{{ watermark }}' {%- endif %}
;

{#- gated for performance reasons - if you don't want iceberg, you shouldn't pay the latency penalty -#}
{%- if adapter.behavior.enable_iceberg_materializations.no_warn %}
select all_objects.*, all_tables.IS_ICEBERG as "is_iceberg"
from table(result_scan(last_query_id(-1))) all_objects
left join {{ schema.database }}.INFORMATION_SCHEMA.tables as all_tables
on all_tables.table_name = all_objects."name"
and all_tables.table_schema = all_objects."schema_name"
and all_tables.table_catalog = all_objects."database_name"
;
{%- endif -%}

{%- endset -%}

{%- do return(_sql) -%}

{% endmacro %}

{#-- RELATIONS DISPATCHED MACROS --#}

{#-- From: macros\relations\view\create.sql --#}
{% macro oefsnowflake__create_or_replace_view() %}
  {%- set identifier = model['alias'] -%}

  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}
  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}

  {%- set target_relation = api.Relation.create(
      identifier=identifier, schema=schema, database=database,
      type='view') -%}
  {% set grant_config = config.get('grants') %}

  {{ run_hooks(pre_hooks) }}

  -- If there's a table with the same name and we weren't told to full refresh,
  -- that's an error. If we were told to full refresh, drop it. This behavior differs
  -- for Snowflake and BigQuery, so multiple dispatch is used.
  {%- if old_relation is not none and not old_relation.is_view -%}
    {{ handle_existing_table(should_full_refresh(), old_relation) }}
  {%- endif -%}

  -- build model
  {% call statement('main') -%}
    {{ get_create_view_as_sql(target_relation, sql) }}
  {%- endcall %}

  {% set should_revoke = should_revoke(exists_as_view, full_refresh_mode=True) %}
  {% do apply_grants(target_relation, grant_config, should_revoke=should_revoke) %}

  {{ run_hooks(post_hooks) }}

  {{ return({'relations': [target_relation]}) }}

{% endmacro %}

{#-- From: macros\relations\dynamic_table\describe.sql --#}
{% macro oefsnowflake__describe_dynamic_table(relation) %}
{#-
    Get all relevant metadata about a dynamic table

    Args:
    - relation: SnowflakeRelation - the relation to describe
    Returns:
        A dictionary with one or two entries depending on whether iceberg is enabled:
        - dynamic_table: the metadata associated with an info schema dynamic table
-#}
    {%- set _dynamic_table_sql -%}
    alter session set quoted_identifiers_ignore_case = false;
    show dynamic tables
        like '{{ relation.identifier }}'
        in schema {{ relation.database }}.{{ relation.schema }}
    ;
    select
        "name",
        "schema_name",
        "database_name",
        "text",
        "target_lag",
        "warehouse",
        "refresh_mode"
    from table(result_scan(last_query_id()))
    ;
    {%- endset -%}

    {%- set results = {'dynamic_table': run_query(_dynamic_table_sql)} -%}

    alter session unset quoted_identifiers_ignore_case;

    {%- do return(results) -%}

{% endmacro %}

{#-- From: macros\relations\create.sql --#}
{% macro oefsnowflake__get_create_sql(relation, sql) %}

    {% if relation.is_dynamic_table %}
        {{ oefsnowflake__get_create_dynamic_table_as_sql(relation, sql) }}

    {% else %}
        {{ default__get_create_sql(relation, sql) }}

    {% endif %}

{% endmacro %}

{#-- From: macros\relations\dynamic_table\drop.sql --#}
{% macro oefsnowflake__get_drop_dynamic_table_sql(relation) %}
    drop dynamic table if exists {{ relation }}
{% endmacro %}

{#-- From: macros\relations\drop.sql --#}
{% macro oefsnowflake__get_drop_sql(relation) %}

    {% if relation.is_dynamic_table %}
        {{ oefsnowflake__get_drop_dynamic_table_sql(relation) }}

    {% else %}
        {{ default__get_drop_sql(relation) }}

    {% endif %}

{% endmacro %}

{#-- From: macros\relations\table\drop.sql --#}
{% macro oefsnowflake__get_drop_table_sql(relation) %}
    drop table if exists {{ relation }} cascade
{% endmacro %}

{#-- From: macros\relations\view\drop.sql --#}
{% macro oefsnowflake__get_drop_view_sql(relation) %}
    drop view if exists {{ relation }} cascade
{% endmacro %}

{#-- From: macros\relations\replace.sql --#}
{% macro oefsnowflake__get_replace_sql(existing_relation, target_relation, sql) %}

    {% if existing_relation.is_dynamic_table and target_relation.is_dynamic_table %}
        {{ oefsnowflake__get_replace_dynamic_table_sql(target_relation, sql) }}

    {% else %}
        {{ default__get_replace_sql(existing_relation, target_relation, sql) }}

    {% endif %}

{% endmacro %}

{#-- From: macros\relations\table\replace.sql --#}
{% macro oefsnowflake__get_replace_table_sql(relation, sql) %}
    {{ oefsnowflake__create_table_as(False, relation, sql) }}
{% endmacro %}

{#-- From: macros\relations\view\replace.sql --#}
{% macro oefsnowflake__get_replace_view_sql(relation, sql) %}
    {{ oefsnowflake__create_view_as(relation, sql) }}
{% endmacro %}

{#-- RELATIONS HELPER MACROS --#}

{#-- From: macros\relations\table\create.sql --#}
{% macro py_write_table(compiled_code, target_relation) %}

{%- set catalog_relation = adapter.build_catalog_relation(config.model) -%}

{% if catalog_relation.is_transient %}
    {%- set table_type='transient' -%}
{% endif %}

{{ compiled_code }}


def materialize(session, df, target_relation):
    # make sure pandas exists
    import importlib.util
    package_name = 'pandas'
    if importlib.util.find_spec(package_name):
        import pandas
        if isinstance(df, pandas.core.frame.DataFrame):
            session.use_database(target_relation.database)
            session.use_schema(target_relation.schema)
            # session.write_pandas does not have overwrite function
            df = session.createDataFrame(df)
    {% set target_relation_name = resolve_model_name(target_relation) %}
    df.write.mode("overwrite").save_as_table('{{ target_relation_name }}', table_type='{{table_type}}')


def main(session):
    dbt = dbtObj(session.table)
    df = model(dbt, session)
    materialize(session, df, dbt.this)
    return "OK"

{% endmacro %}

{#-- UTILS DISPATCHED MACROS --#}

{#-- From: macros\utils\cast.sql --#}
{% macro oefsnowflake__cast(field, type) %}
    {% if (type|upper == "GEOGRAPHY") -%}
        to_geography({{field}})
    {% elif (type|upper == "GEOMETRY") -%}
        to_geometry({{field}})
    {% else -%}
        cast({{field}} as {{type}})
    {% endif -%}
{% endmacro %}

{#-- From: macros\utils\timestamps.sql --#}
{% macro oefsnowflake__current_timestamp_backcompat() %}
  current_timestamp::{{ type_timestamp() }}
{% endmacro %}

{#-- From: macros\utils\timestamps.sql --#}
{% macro oefsnowflake__current_timestamp_in_utc_backcompat() %}
  convert_timezone('UTC', {{ oefsnowflake__current_timestamp_backcompat() }})::{{ type_timestamp() }}
{% endmacro %}

{#-- From: macros\utils\safe_cast.sql --#}
{% macro oefsnowflake__safe_cast(field, type) %}
    {% if type|upper == "GEOMETRY" -%}
        try_to_geometry({{field}})
    {% elif type|upper == "GEOGRAPHY" -%}
        try_to_geography({{field}})
    {% elif type|upper != "VARIANT" -%}
        {#-- Snowflake try_cast does not support casting to variant, and expects the field as a string --#}
        {% set field_as_string =  dbt.string_literal(field) if field is number else field %}
        try_cast({{field_as_string}} as {{type}})
    {% else -%}
        {{ adapter.dispatch('cast', 'dbt')(field, type) }}
    {% endif -%}
{% endmacro %}

{#-- UTILS HELPER MACROS --#}

{#-- From: macros\utils\optional.sql --#}
{% macro optional(name, value, quote_char = '', equals_char = '= ') %}
{#-
--  Insert optional DDL parameters only when their value is provided; makes DDL statements more readable
--
--  Args:
--  - name: the name of the DDL option
--  - value: the value of the DDL option, may be None
--  - quote_char: the quote character to use (e.g. '"', '(', etc.), leave blank if unnecessary
--  - equals_char: the equals character to use (e.g. '= ')
--  Returns:
--      If the value is not None (e.g. provided by the user), return the option setting DDL
--      If the value is None, return an empty string
-#}
{%- set quote_char_right = ')' if quote_char == '(' else quote_char -%}
{% if value is not none %}{{ name }} {{ equals_char }}{{ quote_char }}{{ value }}{{ quote_char_right }}{% endif %}
{% endmacro %}